{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph) #tokeninsing sentences\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(paragraph) #tokenising words\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_temp = paragraph.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph_temp)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\Darsh\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "me\n",
      "my\n",
      "myself\n",
      "we\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "you\n",
      "you're\n",
      "you've\n",
      "you'll\n",
      "you'd\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "he\n",
      "him\n",
      "his\n",
      "himself\n",
      "she\n",
      "she's\n",
      "her\n",
      "hers\n",
      "herself\n",
      "it\n",
      "it's\n",
      "its\n",
      "itself\n",
      "they\n",
      "them\n",
      "their\n",
      "theirs\n",
      "themselves\n",
      "what\n",
      "which\n",
      "who\n",
      "whom\n",
      "this\n",
      "that\n",
      "that'll\n",
      "these\n",
      "those\n",
      "am\n",
      "is\n",
      "are\n",
      "was\n",
      "were\n",
      "be\n",
      "been\n",
      "being\n",
      "have\n",
      "has\n",
      "had\n",
      "having\n",
      "do\n",
      "does\n",
      "did\n",
      "doing\n",
      "a\n",
      "an\n",
      "the\n",
      "and\n",
      "but\n",
      "if\n",
      "or\n",
      "because\n",
      "as\n",
      "until\n",
      "while\n",
      "of\n",
      "at\n",
      "by\n",
      "for\n",
      "with\n",
      "about\n",
      "against\n",
      "between\n",
      "into\n",
      "through\n",
      "during\n",
      "before\n",
      "after\n",
      "above\n",
      "below\n",
      "to\n",
      "from\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "over\n",
      "under\n",
      "again\n",
      "further\n",
      "then\n",
      "once\n",
      "here\n",
      "there\n",
      "when\n",
      "where\n",
      "why\n",
      "how\n",
      "all\n",
      "any\n",
      "both\n",
      "each\n",
      "few\n",
      "more\n",
      "most\n",
      "other\n",
      "some\n",
      "such\n",
      "no\n",
      "nor\n",
      "not\n",
      "only\n",
      "own\n",
      "same\n",
      "so\n",
      "than\n",
      "too\n",
      "very\n",
      "s\n",
      "t\n",
      "can\n",
      "will\n",
      "just\n",
      "don\n",
      "don't\n",
      "should\n",
      "should've\n",
      "now\n",
      "d\n",
      "ll\n",
      "m\n",
      "o\n",
      "re\n",
      "ve\n",
      "y\n",
      "ain\n",
      "aren\n",
      "aren't\n",
      "couldn\n",
      "couldn't\n",
      "didn\n",
      "didn't\n",
      "doesn\n",
      "doesn't\n",
      "hadn\n",
      "hadn't\n",
      "hasn\n",
      "hasn't\n",
      "haven\n",
      "haven't\n",
      "isn\n",
      "isn't\n",
      "ma\n",
      "mightn\n",
      "mightn't\n",
      "mustn\n",
      "mustn't\n",
      "needn\n",
      "needn't\n",
      "shan\n",
      "shan't\n",
      "shouldn\n",
      "shouldn't\n",
      "wasn\n",
      "wasn't\n",
      "weren\n",
      "weren't\n",
      "won\n",
      "won't\n",
      "wouldn\n",
      "wouldn't\n"
     ]
    }
   ],
   "source": [
    "for word in stopwords.words('english'):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india .',\n",
       " '3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
       " 'alexand onward , greek , turk , mogul , portugues , british , french , dutch , came loot us , took .',\n",
       " 'yet done nation .',\n",
       " 'conquer anyon .',\n",
       " 'grab land , cultur , histori tri enforc way life .',\n",
       " '?',\n",
       " 'respect freedom others.that first vision freedom .',\n",
       " 'believ india got first vision 1857 , start war independ .',\n",
       " 'freedom must protect nurtur build .',\n",
       " 'free , one respect us .',\n",
       " 'second vision india ’ develop .',\n",
       " 'fifti year develop nation .',\n",
       " 'time see develop nation .',\n",
       " 'among top 5 nation world term gdp .',\n",
       " '10 percent growth rate area .',\n",
       " 'poverti level fall .',\n",
       " 'achiev global recognis today .',\n",
       " 'yet lack self-confid see develop nation , self-reli self-assur .',\n",
       " '’ incorrect ?',\n",
       " 'third vision .',\n",
       " 'india must stand world .',\n",
       " 'believ unless india stand world , one respect us .',\n",
       " 'strength respect strength .',\n",
       " 'must strong militari power also econom power .',\n",
       " 'must go hand-in-hand .',\n",
       " 'good fortun work three great mind .',\n",
       " 'dr. vikram sarabhai dept .',\n",
       " 'space , professor satish dhawan , succeed dr. brahm prakash , father nuclear materi .',\n",
       " 'lucki work three close consid great opportun life .',\n",
       " 'see four mileston career']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_temp = paragraph.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph_temp)\n",
    "lemmatize = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatize.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india .',\n",
       " '3000 year history , people world come invaded u , captured land , conquered mind .',\n",
       " 'alexander onwards , greek , turk , mogul , portuguese , british , french , dutch , came looted u , took .',\n",
       " 'yet done nation .',\n",
       " 'conquered anyone .',\n",
       " 'grabbed land , culture , history tried enforce way life .',\n",
       " '?',\n",
       " 'respect freedom others.that first vision freedom .',\n",
       " 'believe india got first vision 1857 , started war independence .',\n",
       " 'freedom must protect nurture build .',\n",
       " 'free , one respect u .',\n",
       " 'second vision india ’ development .',\n",
       " 'fifty year developing nation .',\n",
       " 'time see developed nation .',\n",
       " 'among top 5 nation world term gdp .',\n",
       " '10 percent growth rate area .',\n",
       " 'poverty level falling .',\n",
       " 'achievement globally recognised today .',\n",
       " 'yet lack self-confidence see developed nation , self-reliant self-assured .',\n",
       " '’ incorrect ?',\n",
       " 'third vision .',\n",
       " 'india must stand world .',\n",
       " 'believe unless india stand world , one respect u .',\n",
       " 'strength respect strength .',\n",
       " 'must strong military power also economic power .',\n",
       " 'must go hand-in-hand .',\n",
       " 'good fortune worked three great mind .',\n",
       " 'dr. vikram sarabhai dept .',\n",
       " 'space , professor satish dhawan , succeeded dr. brahm prakash , father nuclear material .',\n",
       " 'lucky worked three closely consider great opportunity life .',\n",
       " 'see four milestone career']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " paragraph_temp = paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z0-9]',' ',sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " '3000 year history people world come invaded u captured land conquered mind',\n",
       " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took',\n",
       " 'yet done nation',\n",
       " 'conquered anyone',\n",
       " 'grabbed land culture history tried enforce way life',\n",
       " '',\n",
       " 'respect freedom others first vision freedom',\n",
       " 'believe india got first vision 1857 started war independence',\n",
       " 'freedom must protect nurture build',\n",
       " 'free one respect u',\n",
       " 'second vision india development',\n",
       " 'fifty year developing nation',\n",
       " 'time see developed nation',\n",
       " 'among top 5 nation world term gdp',\n",
       " '10 percent growth rate area',\n",
       " 'poverty level falling',\n",
       " 'achievement globally recognised today',\n",
       " 'yet lack self confidence see developed nation self reliant self assured',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believe unless india stand world one respect u',\n",
       " 'strength respect strength',\n",
       " 'must strong military power also economic power',\n",
       " 'must go hand hand',\n",
       " 'good fortune worked three great mind',\n",
       " 'dr vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeeded dr brahm prakash father nuclear material',\n",
       " 'lucky worked three closely consider great opportunity life',\n",
       " 'see four milestone career']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_temp = paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z0-9]',' ',sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.32348709, ..., 0.24491817, 0.28871979,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_temp = paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\[[0-9]*\\]',' ',paragraph_temp)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\d',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have three visions for india. in years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. from alexander onwards, the greeks, the turks, the moguls, the portuguese, the british, the french, the dutch, all of them came and looted us, took over what was ours. yet we have not done this to any other nation. we have not conquered anyone. we have not grabbed their land, their culture, their history and tried to enforce our way of life on them. why? because we respect the freedom of others.that is why my first vision is that of freedom. i believe that india got its first vision of this in , when we started the war of independence. it is this freedom that we must protect and nurture and build on. if we are not free, no one will respect us. my second vision for india’s development. for fifty years we have been a developing nation. it is time we see ourselves as a developed nation. we are among the top nations of the world in terms of gdp. we have a percent growth rate in most areas. our poverty levels are falling. our achievements are being globally recognised today. yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. isn’t this incorrect? i have a third vision. india must stand up to the world. because i believe that unless india stands up to the world, no one will respect us. only strength respects strength. we must be strong not only as a military power but also as an economic power. both must go hand-in-hand. my good fortune was to have worked with three great minds. dr. vikram sarabhai of the dept. of space, professor satish dhawan, who succeeded him and dr. brahm prakash, father of nuclear material. i was lucky to have worked with all three of them closely and consider this the great opportunity of my life. i see four milestones in my career'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'three': <gensim.models.keyedvectors.Vocab at 0x1a23d4dcf88>,\n",
       " 'visions': <gensim.models.keyedvectors.Vocab at 0x1a23d4dc388>,\n",
       " 'india': <gensim.models.keyedvectors.Vocab at 0x1a23d4dc5c8>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x1a23d4dce08>,\n",
       " 'years': <gensim.models.keyedvectors.Vocab at 0x1a23d4df208>,\n",
       " 'history': <gensim.models.keyedvectors.Vocab at 0x1a23d4dfb08>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x1a23d4df2c8>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x1a23d4df5c8>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x1a23d4dcbc8>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x1a23d4dfbc8>,\n",
       " 'invaded': <gensim.models.keyedvectors.Vocab at 0x1a23d4dfc88>,\n",
       " 'us': <gensim.models.keyedvectors.Vocab at 0x1a23d4dff88>,\n",
       " 'captured': <gensim.models.keyedvectors.Vocab at 0x1a23d4dfec8>,\n",
       " 'lands': <gensim.models.keyedvectors.Vocab at 0x1a23d4df688>,\n",
       " 'conquered': <gensim.models.keyedvectors.Vocab at 0x1a23d4df808>,\n",
       " 'minds': <gensim.models.keyedvectors.Vocab at 0x1a23d4df088>,\n",
       " 'alexander': <gensim.models.keyedvectors.Vocab at 0x1a23d4df988>,\n",
       " 'onwards': <gensim.models.keyedvectors.Vocab at 0x1a23d4df448>,\n",
       " 'greeks': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2d48>,\n",
       " 'turks': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2c88>,\n",
       " 'moguls': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2308>,\n",
       " 'portuguese': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2a88>,\n",
       " 'british': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2848>,\n",
       " 'french': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2f88>,\n",
       " 'dutch': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2988>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2a08>,\n",
       " 'looted': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2d08>,\n",
       " 'took': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2a48>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2e88>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2e08>,\n",
       " 'nation': <gensim.models.keyedvectors.Vocab at 0x1a23d4e29c8>,\n",
       " 'anyone': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2c08>,\n",
       " 'grabbed': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2fc8>,\n",
       " 'land': <gensim.models.keyedvectors.Vocab at 0x1a23d4e2c48>,\n",
       " 'culture': <gensim.models.keyedvectors.Vocab at 0x1a23d50fc08>,\n",
       " 'tried': <gensim.models.keyedvectors.Vocab at 0x1a23d50f0c8>,\n",
       " 'enforce': <gensim.models.keyedvectors.Vocab at 0x1a23d50fb08>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x1a23d50f388>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x1a23d50f348>,\n",
       " '?': <gensim.models.keyedvectors.Vocab at 0x1a23d4deec8>,\n",
       " 'respect': <gensim.models.keyedvectors.Vocab at 0x1a23d4de988>,\n",
       " 'freedom': <gensim.models.keyedvectors.Vocab at 0x1a23d4de688>,\n",
       " 'others.that': <gensim.models.keyedvectors.Vocab at 0x1a23d4ded48>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x1a23d4de448>,\n",
       " 'vision': <gensim.models.keyedvectors.Vocab at 0x1a23d4de808>,\n",
       " 'believe': <gensim.models.keyedvectors.Vocab at 0x1a23d4deb08>,\n",
       " 'got': <gensim.models.keyedvectors.Vocab at 0x1a23d4de208>,\n",
       " 'started': <gensim.models.keyedvectors.Vocab at 0x1a23d4de388>,\n",
       " 'war': <gensim.models.keyedvectors.Vocab at 0x1a23d4ffbc8>,\n",
       " 'independence': <gensim.models.keyedvectors.Vocab at 0x1a23d4ffa88>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x1a23d4ff548>,\n",
       " 'protect': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6388>,\n",
       " 'nurture': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6108>,\n",
       " 'build': <gensim.models.keyedvectors.Vocab at 0x1a23d4c62c8>,\n",
       " 'free': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6508>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x1a23d4c60c8>,\n",
       " 'second': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6348>,\n",
       " '’': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6848>,\n",
       " 'development': <gensim.models.keyedvectors.Vocab at 0x1a23d4c68c8>,\n",
       " 'fifty': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6288>,\n",
       " 'developing': <gensim.models.keyedvectors.Vocab at 0x1a23d4c61c8>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x1a23d4c64c8>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6548>,\n",
       " 'developed': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6448>,\n",
       " 'among': <gensim.models.keyedvectors.Vocab at 0x1a23d4c69c8>,\n",
       " 'top': <gensim.models.keyedvectors.Vocab at 0x1a23d4c6188>,\n",
       " 'nations': <gensim.models.keyedvectors.Vocab at 0x1a23d4f9a88>,\n",
       " 'terms': <gensim.models.keyedvectors.Vocab at 0x1a23d4f9048>,\n",
       " 'gdp': <gensim.models.keyedvectors.Vocab at 0x1a23d4f9e88>,\n",
       " 'percent': <gensim.models.keyedvectors.Vocab at 0x1a23d4f9c08>,\n",
       " 'growth': <gensim.models.keyedvectors.Vocab at 0x1a23d4b5c08>,\n",
       " 'rate': <gensim.models.keyedvectors.Vocab at 0x1a23d4f4f88>,\n",
       " 'areas': <gensim.models.keyedvectors.Vocab at 0x1a23d4f4a48>,\n",
       " 'poverty': <gensim.models.keyedvectors.Vocab at 0x1a23d4f4dc8>,\n",
       " 'levels': <gensim.models.keyedvectors.Vocab at 0x1a23d4f4948>,\n",
       " 'falling': <gensim.models.keyedvectors.Vocab at 0x1a23d4f4608>,\n",
       " 'achievements': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef388>,\n",
       " 'globally': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef648>,\n",
       " 'recognised': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef548>,\n",
       " 'today': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef408>,\n",
       " 'lack': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef108>,\n",
       " 'self-confidence': <gensim.models.keyedvectors.Vocab at 0x1a23d4efa48>,\n",
       " 'self-reliant': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef488>,\n",
       " 'self-assured': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef308>,\n",
       " 'incorrect': <gensim.models.keyedvectors.Vocab at 0x1a23d4ef508>,\n",
       " 'third': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea308>,\n",
       " 'stand': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea508>,\n",
       " 'unless': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea348>,\n",
       " 'stands': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea6c8>,\n",
       " 'strength': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea7c8>,\n",
       " 'respects': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea688>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x1a23d4eaac8>,\n",
       " 'military': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea9c8>,\n",
       " 'power': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea908>,\n",
       " 'also': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea748>,\n",
       " 'economic': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea488>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea548>,\n",
       " 'hand-in-hand': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea0c8>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea948>,\n",
       " 'fortune': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea588>,\n",
       " 'worked': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea808>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea288>,\n",
       " 'dr.': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea048>,\n",
       " 'vikram': <gensim.models.keyedvectors.Vocab at 0x1a23d4ea148>,\n",
       " 'sarabhai': <gensim.models.keyedvectors.Vocab at 0x1a23d4d7448>,\n",
       " 'dept': <gensim.models.keyedvectors.Vocab at 0x1a23d4d7d48>,\n",
       " 'space': <gensim.models.keyedvectors.Vocab at 0x1a23d4d7c88>,\n",
       " 'professor': <gensim.models.keyedvectors.Vocab at 0x1a23d4d78c8>,\n",
       " 'satish': <gensim.models.keyedvectors.Vocab at 0x1a23d4d7bc8>,\n",
       " 'dhawan': <gensim.models.keyedvectors.Vocab at 0x1a23d4e51c8>,\n",
       " 'succeeded': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5048>,\n",
       " 'brahm': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5208>,\n",
       " 'prakash': <gensim.models.keyedvectors.Vocab at 0x1a23d4e50c8>,\n",
       " 'father': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5088>,\n",
       " 'nuclear': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5cc8>,\n",
       " 'material': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5dc8>,\n",
       " 'lucky': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5d08>,\n",
       " 'closely': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5a88>,\n",
       " 'consider': <gensim.models.keyedvectors.Vocab at 0x1a23d4e59c8>,\n",
       " 'opportunity': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5d48>,\n",
       " 'four': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5e08>,\n",
       " 'milestones': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5b48>,\n",
       " 'career': <gensim.models.keyedvectors.Vocab at 0x1a23d4e5d88>}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.wv['war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4130809e-03,  6.9100049e-04, -2.2070820e-03,  1.8709290e-03,\n",
       "       -2.1638612e-03, -3.5173036e-03, -4.7735604e-03,  4.7195745e-03,\n",
       "       -3.4261686e-03,  3.4640352e-03, -2.5655692e-03,  3.0639003e-05,\n",
       "        4.8316596e-03,  2.7272332e-04, -3.9573419e-03,  4.6756198e-03,\n",
       "        3.1179022e-03, -1.3317538e-03, -3.8148612e-03,  4.6042996e-03,\n",
       "        1.1717590e-03, -4.8270286e-04, -5.2912120e-04,  1.4329959e-03,\n",
       "        3.4840094e-04, -1.3716390e-03, -7.3806330e-04,  4.3382430e-03,\n",
       "        1.2353808e-03,  6.7131856e-05,  8.8512670e-04,  4.3794606e-03,\n",
       "       -1.3321663e-03,  2.4679077e-03, -2.7022578e-04,  3.8330704e-03,\n",
       "       -3.2232665e-03, -1.9751058e-03,  2.4520229e-03,  2.4230285e-03,\n",
       "       -3.0213774e-03,  1.3442403e-03,  2.0451618e-03,  1.2366392e-04,\n",
       "        1.9690935e-03,  3.1825269e-03, -3.4274715e-03,  9.6039119e-04,\n",
       "        1.1368066e-03,  1.4801477e-03,  2.3023337e-03, -1.3775070e-03,\n",
       "       -2.5098873e-03,  1.6968894e-04, -1.1132974e-03,  4.5759496e-03,\n",
       "        3.2468906e-03,  3.9495490e-03, -4.6011369e-04,  3.2456999e-03,\n",
       "        2.2965285e-03,  3.3222199e-03, -4.1143303e-03,  2.6676382e-03,\n",
       "        3.7965219e-04, -3.5142309e-03,  3.5271232e-03,  4.2769588e-03,\n",
       "        2.5106492e-03, -2.7655205e-03,  4.4483505e-03,  1.3019999e-03,\n",
       "        4.5205457e-03, -2.5937022e-03, -1.2397437e-04, -3.1168882e-03,\n",
       "       -1.0072081e-03,  2.7152458e-03,  2.8916509e-03, -2.9981829e-05,\n",
       "       -4.1241595e-03, -4.4268821e-03,  1.6568370e-04, -1.5632652e-03,\n",
       "       -3.0033239e-03, -1.5322861e-03, -3.5961301e-03,  1.7010579e-03,\n",
       "       -4.6502026e-03, -3.7027888e-03, -4.5930552e-03, -2.5438389e-03,\n",
       "        3.4120856e-03, -2.6560188e-03, -4.3717646e-03, -4.2684577e-04,\n",
       "       -1.5365770e-04, -3.2791174e-03, -3.1826501e-03,  3.1785374e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = model.wv.most_similar('vikram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('visions', 0.2996618449687958),\n",
       " ('enforce', 0.26591813564300537),\n",
       " ('time', 0.25080180168151855),\n",
       " ('done', 0.22729068994522095),\n",
       " ('achievements', 0.21558740735054016),\n",
       " ('three', 0.20790693163871765),\n",
       " ('second', 0.19778111577033997),\n",
       " ('strong', 0.17716610431671143),\n",
       " ('nation', 0.15891189873218536),\n",
       " ('moguls', 0.15819576382637024)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
